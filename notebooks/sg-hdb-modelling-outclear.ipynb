{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://gallery.mailchimp.com/f98d5ac0a3fbbdcdda35136ab/images/2002af76-5fd4-4185-9d49-28558b6b8772.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sg-hdb-resale-bokeh` \n",
    "# Part 2: Model Training\n",
    "What we have done so far is to extract data from the .csv files, do some preliminary transformation to the data, and then loading all of it into an SQLite database. The next step is to work towards creating a simple predictive model for us to predict the price of a resale HDB unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_engine = create_engine('sqlite:///../data/processed/sg_hdb.db')\n",
    "# Simple query to get the whole table\n",
    "query = \"SELECT * FROM sg_hdb_resale\"\n",
    "# Store result of query in a pandas dataframe\n",
    "sg_hdb_resale_df = pd.read_sql_query(query, sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observe result of query executed\n",
    "sg_hdb_resale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the other table containing the resale HDB price index\n",
    "query = \"SELECT * FROM sg_hdb_pi\"\n",
    "sg_hdb_pi = pd.read_sql_query(query, sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to inspect the data types of the imported dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_resale_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_pi.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next immediate set of steps would consist of associating a price index from `sg_hdb_pi` to each observation belonging to `sg_hdb_resale_df` and afterwards adjusting the resale price values according to the indexes. This is akin to a left join but there's no key to relate both dataframes.\n",
    "\n",
    "We first have to create a column for `sg_hdb_resale_df` stating the year and quarter for each transaction/observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'month' column to a datetime format\n",
    "sg_hdb_resale_df['month'] = pd.to_datetime(sg_hdb_resale_df.month, format='%Y-%m')\n",
    "sg_hdb_resale_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_resale_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will take in the year and month properties from the 'month' column to get a single output containing the year and quarter of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_quarter(x):\n",
    "    year = x.year\n",
    "    # Floor division for the month property to get the month's quarter\n",
    "    quarter = ((x.month-1)//3)+1\n",
    "    # Combining the year and quarter properties into a single output\n",
    "    year_quarter = '{}-Q{}'.format(year, quarter)\n",
    "    return year_quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we iterate the function above to each observation using the `map` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_resale_df['resale_quarter'] = sg_hdb_resale_df['month'].map(get_year_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_resale_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current no. of observations\n",
    "len(sg_hdb_resale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have the resale price index up until Q4 of 2018, we would have to filter out transactions recorded after 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_resale_df = sg_hdb_resale_df[sg_hdb_resale_df['month'] < pd.to_datetime(2019, format='%Y')]\n",
    "# Now the current no. of observations has changed since some have been filtered out\n",
    "len(sg_hdb_resale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the common column to match both `sg_hdb_resale_df` with `sg_hdb_pi`, we would like to do a left join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_resale_df = pd.merge(sg_hdb_resale_df, sg_hdb_pi, left_on='resale_quarter', right_on='quarter', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_resale_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the join, we would like to apply the indexes to the recorded resale prices. Create the function that is able to do this for every observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_resale_price(x):\n",
    "    # Converting indexes to multipliers\n",
    "    index_multiplier = x['index']/100\n",
    "    # Applying multiplier to observation's resale price\n",
    "    adjusted_price = x['resale_price'] * index_multiplier\n",
    "    return adjusted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column 'adjusted_resale_price' to contain these new derived values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_resale_df['adjusted_resale_price'] = adjust_resale_price(sg_hdb_resale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_hdb_resale_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have adjusted the resale prices according to the allocated price indexes, we are now going to build a simple linear regression model that allows us to predict a resale price of a unit, given a value of `floor_area_sqm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_resale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check number of null values across all columns\n",
    "sg_hdb_resale_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create 2 separate series containing the predictor and response values to train our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_X = sg_hdb_resale_df['floor_area_sqm'].values\n",
    "sg_hdb_Y = sg_hdb_resale_df['adjusted_resale_price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a model, we have to create a train-test split to check the accuracy/performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_X_train, sg_hdb_X_test, sg_hdb_Y_train, sg_hdb_Y_test = sklearn.model_selection.train_test_split(\n",
    "    sg_hdb_X, sg_hdb_Y,\n",
    "    test_size=0.3, random_state=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping needed when using a single variable for predictor\n",
    "sg_hdb_X_train = sg_hdb_X_train.reshape(-1,1)\n",
    "sg_hdb_X_test = sg_hdb_X_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna create a simple linear regression model (a.k.a best fit line) from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model\n",
    "lm = LinearRegression()\n",
    "# Create model from the train sets\n",
    "lm.fit(sg_hdb_X_train, sg_hdb_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To observe the model's coefficients\n",
    "print('Coefficients: \\n X:', lm.coef_,'\\n c:', lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the model, we are going to evaluate its performance by pitting it against the test set.\n",
    "\n",
    "First, we use the linear model to provide us with the predictions derived from the values in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hdb_Y_pred = lm.predict(sg_hdb_X_test)\n",
    "sg_hdb_Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter, we are going to calculate the errors, pitting the predicted values with actual historical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine fitness of model\n",
    "r2_score(sg_hdb_Y_test, sg_hdb_Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the model have such a score? Well, let's check how the linear model was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(sg_hdb_X_test, sg_hdb_Y_test, color='red')\n",
    "plt.plot(sg_hdb_X_test, sg_hdb_Y_pred, color='blue')\n",
    "plt.title(\" SG HDB Resale \")\n",
    "plt.xlabel('floor_area_sqm')\n",
    "plt.ylabel(\"pred_resale_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heavily sparsed set of data points can hardly be described by a single linear regression model, hence the low value of fitness.\n",
    "\n",
    "For the sake of this exercise, let us just proceed and export (serialise) this model for deployment. Save the model under a name, for example like the one below: 'sg_hdb_lm_v1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify output location of model to be serialised\n",
    "file_loc_name = '../models/sg_hdb_lm_v1.pkl'\n",
    "pickle.dump(lm, open(file_loc_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we just do a quick test by loading the model and then doing a single prediction to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading saved model\n",
    "loaded_model = pickle.load(open(file_loc_name, 'rb'))\n",
    "# Create a test value for test prediction\n",
    "# Test value has to be contained in a numpy array format hence np.array\n",
    "test_val = np.array(65)\n",
    "# Reshaping value before feeding to .predict function\n",
    "test_val_reshape = test_val.reshape(-1, 1)\n",
    "# Conduct prediction\n",
    "result = loaded_model.predict(test_val_reshape)\n",
    "# Print out result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have exported this model, time to create a simple API (Application Programming Interface) that allows us to use the model, potentially remotely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
